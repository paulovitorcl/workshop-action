# AI Helm Values Generator

Um GitHub Action que utiliza Intelig√™ncia Artificial para gerar valores otimizados do Helm com base em an√°lise de contexto operacional.

## üéØ Funcionalidades

- Analisa incidentes operacionais e m√©tricas para identificar problemas
- Gera recomenda√ß√µes inteligentes para valores do Helm
- Suporta m√∫ltiplos provedores de IA (GitHub Models, OpenAI)
- Aplica automaticamente as recomenda√ß√µes aos valores atuais
- Fornece justificativas detalhadas para cada mudan√ßa

## üìã Inputs

| Input | Descri√ß√£o | Obrigat√≥rio | Padr√£o |
|-------|-----------|-------------|---------|
| `app_name` | Nome da aplica√ß√£o | ‚úÖ | - |
| `environment` | Ambiente de deploy (dev/staging/prod) | ‚úÖ | - |
| `current_values` | Conte√∫do atual do values.yaml (codificado em base64) | ‚úÖ | - |
| `operational_context` | Contexto operacional em YAML (codificado em base64) | ‚úÖ | - |
| `helm_templates` | Conte√∫do dos templates Helm (array JSON) | ‚ùå | `[]` |
| `ai_provider` | Provedor de IA (github/openai) | ‚ùå | `copilot` |
| `ai_token` | Token da API do provedor de IA | ‚ùå | - |
| `ai_model` | Modelo de IA a utilizar | ‚ùå | `gpt-4o` |

## üì§ Outputs

| Output | Descri√ß√£o |
|--------|-----------|
| `generated_values` | Conte√∫do do values.yaml gerado |
| `ai_analysis` | An√°lise e recomenda√ß√µes da IA |
| `changes_summary` | Resumo das mudan√ßas realizadas |

## üöÄ Como Usar

### Exemplo B√°sico

```yaml
- name: Gerar valores otimizados com IA
  uses: ./
  with:
    app_name: "minha-app"
    environment: "production"
    current_values: ${{ env.CURRENT_VALUES_B64 }}
    operational_context: ${{ env.OPERATIONAL_CONTEXT_B64 }}
    ai_provider: "copilot"
    ai_token: ${{ secrets.GITHUB_TOKEN }}
```

### Exemplo Completo

```yaml
name: Otimiza√ß√£o Inteligente do Helm
on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Ambiente'
        required: true
        default: 'staging'
        type: choice
        options:
          - dev
          - staging
          - prod

jobs:
  optimize-helm:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Preparar contexto operacional
        run: |
          # Coletar m√©tricas e incidentes recentes
          cat > operational-context.yaml << EOF
          recent_incidents:
            - type: "high_memory_usage"
              description: "Aplica√ß√£o atingiu 95% do limite de mem√≥ria"
              timestamp: "2024-01-15T10:30:00Z"
              severity: "high"
          
          metrics:
            avg_cpu_usage: 0.75
            avg_memory_usage: 0.85
            p99_response_time: 2500ms
            error_rate: 0.05
          
          resource_constraints:
            current_replicas: 3
            max_cpu_per_pod: "1"
            max_memory_per_pod: "2Gi"
          EOF
          
          # Codificar em base64
          echo "OPERATIONAL_CONTEXT_B64=$(cat operational-context.yaml | base64 -w 0)" >> $GITHUB_ENV
          echo "CURRENT_VALUES_B64=$(cat helm/values.yaml | base64 -w 0)" >> $GITHUB_ENV
      
      - name: Gerar valores otimizados
        id: optimize
        uses: ./
        with:
          app_name: "minha-aplicacao"
          environment: ${{ inputs.environment }}
          current_values: ${{ env.CURRENT_VALUES_B64 }}
          operational_context: ${{ env.OPERATIONAL_CONTEXT_B64 }}
          ai_provider: "copilot"
          ai_token: ${{ secrets.GITHUB_TOKEN }}
          ai_model: "gpt-4o"
      
      - name: Salvar valores otimizados
        run: |
          echo "${{ steps.optimize.outputs.generated_values }}" > helm/values-optimized.yaml
          
      - name: Mostrar an√°lise da IA
        run: |
          echo "## ü§ñ An√°lise da IA"
          echo "${{ steps.optimize.outputs.ai_analysis }}"
          echo ""
          echo "## üìä Resumo das Mudan√ßas"
          echo "${{ steps.optimize.outputs.changes_summary }}"
```

## üìä Formato do Contexto Operacional

O contexto operacional deve ser fornecido em formato YAML com a seguinte estrutura:

```yaml
recent_incidents:
  - type: "out_of_memory"
    description: "Pod foi reiniciado por falta de mem√≥ria"
    timestamp: "2024-01-15T10:30:00Z"
    severity: "critical"
  - type: "slow_response"
    description: "Tempo de resposta acima de 5s"
    timestamp: "2024-01-15T11:00:00Z"
    severity: "medium"

metrics:
  avg_cpu_usage: 0.85        # 85% em m√©dia
  avg_memory_usage: 0.90     # 90% em m√©dia
  p99_response_time: 3000ms  # 3 segundos no p99
  error_rate: 0.02           # 2% de taxa de erro
  requests_per_second: 1500

resource_constraints:
  current_replicas: 2
  max_cpu_per_pod: "500m"
  max_memory_per_pod: "1Gi"
  node_capacity: "4 cores, 8Gi RAM"

alerts:
  - name: "HighMemoryUsage"
    status: "firing"
    duration: "5m"
```

## üîß Configura√ß√£o dos Provedores de IA

### GitHub Models (Copilot)
```yaml
ai_provider: "copilot"
ai_token: ${{ secrets.GITHUB_TOKEN }}
ai_model: "gpt-4o"  # ou gpt-4, gpt-3.5-turbo
```

### OpenAI
```yaml
ai_provider: "openai"
ai_token: ${{ secrets.OPENAI_API_KEY }}
ai_model: "gpt-4"  # ou gpt-3.5-turbo
```

## üéØ Tipos de Otimiza√ß√µes

A IA pode sugerir otimiza√ß√µes para:

- **Recursos**: CPU e mem√≥ria (requests/limits)
- **Autoscaling**: Min/max replicas e m√©tricas de escala
- **Health Checks**: Configura√ß√µes de liveness/readiness probes
- **Configura√ß√µes de Pod**: Tolerations, node affinity
- **Networking**: Service e ingress settings

## ‚ö†Ô∏è Requisitos

- GitHub Actions runner
- Token de API v√°lido para o provedor de IA escolhido
- Inputs codificados em base64 (para evitar problemas com caracteres especiais)

## ü§ù Contribuindo

1. Fork este reposit√≥rio
2. Crie uma branch para sua feature
3. Fa√ßa commit das mudan√ßas
4. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT.
